{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Net from scratch [See Paper PDF](https://arxiv.org/pdf/1905.11946.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://d3i71xaburhd42.cloudfront.net/e085a62d97b12eb5efc1a65fbdb87a5acbb75868/4-Table2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Observations:\n",
    "\n",
    "### Observation 1:\n",
    "\n",
    "Scaling up any dimension of network width, depth, or resolution imporves accuracy, but the accuracy gain diminishes for bigger models.\n",
    "\n",
    "### Observation 2:\n",
    "\n",
    "In order to pursue better accuracy and efficiency, it is critical to balance all dimensions of network width, depth and resoultion during ConvNet scaling.\n",
    "\n",
    "![](https://1.bp.blogspot.com/-Cdtb97FtgdA/XO3BHsB7oEI/AAAAAAAAEKE/bmtkonwgs8cmWyI5esVo8wJPnhPLQ5bGQCLcBGAs/s1600/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficinetNet-B0 Architecture\n",
    "\n",
    "### Table showing details of B0 Architecture\n",
    "\n",
    "\n",
    "![EfficientNet Architecture Img](https://miro.medium.com/max/1400/0*6ezHy0HX_lCrJGRS \"EfficinetNet-B0 Architecture\")\n",
    "\n",
    "\n",
    "### See how sub-layer(s) look like\n",
    "![](https://miro.medium.com/max/2000/1*rnhgFRXetwD8PvxhZIpwIA.png)\n",
    "\n",
    "\n",
    "### Sub-Layers are also continious layers! (Dont be scared of the term \"Sub-Layers\") :)\n",
    "We just say them sub-layers because they all have same structures.\n",
    "\n",
    "![](https://www.researchgate.net/profile/Tashin-Ahmed/publication/344410350/figure/fig4/AS:1022373302128641@1620764198841/Architecture-of-EfficientNet-B0-with-MBConv-as-Basic-building-blocks.png \"EfficinetNet-B0 Architecture\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What authors use to get amazing results??\n",
    "\n",
    "**Ans** \n",
    "- SiLU\n",
    "- Auto Augment\n",
    "- Stochastic Depth\n",
    "- Squeeze-and-excitation optimization\n",
    "- Mobile inverted bottleneck MBConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre- requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compound scaling method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T06:35:23.923410Z",
     "start_time": "2022-01-06T06:35:23.906408Z"
    }
   },
   "source": [
    "**Compound Coefficient [φ]**\n",
    "\n",
    "- It uniformaly scales network width, depth and resolution in a principled way.\n",
    "\n",
    "<div style=\"background-color: wheat; padding: 10px\">\n",
    "Depth: d = α^φ\n",
    "width: w = β^φ\n",
    "resolution: r = γ^φ\n",
    "\n",
    "**Constraint**\n",
    "s.t. α · β^2 · γ^2 ≈ 2\n",
    "\n",
    "**Where**\n",
    "α ≥ 1, β ≥ 1, γ ≥ 1\n",
    "\n",
    "Here α, β, γ are the constants that can be determined by a small grid search.\n",
    "</div>\n",
    "\n",
    "- φ is a user specified coefficient that controls how many more resources are available for model scaling. When we have fixed computational budget eg. When we are working with mobile or small computational devices.\n",
    "\n",
    "\n",
    "- **FLOPS** of a regular conv operation is proportional to d, w^2, r^2 i.e. doubling network depth will double FLOPS, but doubling network width or resolution will increase FLOPS by 4 times.\n",
    "\n",
    "\n",
    "- As we know conv op usually dominate the computation cost in convnets, scaling a convnet with the above eq will approx. increase total FLOPS by (α · β^2 · γ^2)^φ or ~ (2)^φ\n",
    "\n",
    "\n",
    "**Q How they find above values  for α, β and γ?**\n",
    "\n",
    "**Ans :** Using Grid search they find that ALPHA = 1.2, BETA = 1.1 and GAMMA = 1.15 are the best values for EfficientNet-B0. After that they fixed α, β, γ as constants and scale up baseline network with different φ, to obtain EfficientNet-B0 to B7 as given above in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient Net main building block is **mobile inverted bottleneck MBConv**, to which they also add **squeeze-and-excitation optimization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile inverted bottleneck MBConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze-and-excitation optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FLOPS (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T07:52:42.636586Z",
     "start_time": "2022-01-06T07:52:42.627350Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCREASE IN TOTAL FLOPS: 1.9203\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CALCULATE INCREASE IN TOTAL FLOPS\n",
    "'''\n",
    "import numpy as np\n",
    "PHI = 1\n",
    "ALPHA = 1.2\n",
    "BETA = 1.1\n",
    "GAMMA = 1.15\n",
    "\n",
    "def calc_FLOPS():\n",
    "    return np.power(np.power(ALPHA, 1) *np.power(BETA, 2) * np.power(GAMMA, 2), PHI)\n",
    "\n",
    "\n",
    "print(f\"INCREASE IN TOTAL FLOPS: {calc_FLOPS():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SiLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Activation Map \n",
    "<a href=\"https://towardsdatascience.com/activation-maps-for-deep-learning-models-in-a-few-lines-of-code-ed9ced1e8d21\">link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T08:58:07.037558Z",
     "start_time": "2022-01-07T08:58:07.032889Z"
    }
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:22.177036Z",
     "start_time": "2022-01-07T13:11:22.173029Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T08:58:30.529167Z",
     "start_time": "2022-01-07T08:58:30.524520Z"
    }
   },
   "source": [
    "## Simple Conv Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Block implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:22.780982Z",
     "start_time": "2022-01-07T13:11:22.773655Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "        '''\n",
    "        groups = in_channels is for depth wise conv\n",
    "        eg \n",
    "        FOR 10x256x256 input data\n",
    "        WHEN groups= 1 THEN  conv kernel will be 10x3x3\n",
    "        WHEN groups= in_channels THEN conv kernel will be 1x3x3\n",
    "        '''\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.cnn = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            groups= groups,\n",
    "            bias= False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.silu = nn.SiLU() # SiLU <-> Swish\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.silu(self.bn(self.cnn(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:23.090628Z",
     "start_time": "2022-01-07T13:11:22.841565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ✅\n"
     ]
    }
   ],
   "source": [
    "batch = 15\n",
    "channels = 10\n",
    "out_channels = 50\n",
    "data = torch.rand(batch, channels, 256, 256)\n",
    "result = CNNBlock(channels, out_channels, kernel_size=3, stride=1,\n",
    "                  padding=0)(data)\n",
    "\n",
    "# Delete variables so that they dont mess up in the later part of code\n",
    "del batch, channels, out_channels, data\n",
    "\n",
    "print(\"Correct ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze and Excitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure shows Squeeze and Excitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![Squeeze Excitation](https://www.researchgate.net/profile/Anabia-Sohail-2/publication/330511306/figure/fig8/AS:717351204966400@1548041263212/Squeeze-and-Excitation-block.ppm \"How Squeeze excitation works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze and Excitation implementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:23.095788Z",
     "start_time": "2022-01-07T13:11:23.092298Z"
    }
   },
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, red_channels):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\n",
    "            nn.Conv2d(in_channels, red_channels, 1), # Squeeze part\n",
    "            nn.SiLU(), # Activation\n",
    "            nn.Conv2d(red_channels, in_channels, 1), # Excitation\n",
    "            nn.Sigmoid() # Activation\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "         return x * self.se(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:23.193202Z",
     "start_time": "2022-01-07T13:11:23.158633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ✅\n"
     ]
    }
   ],
   "source": [
    "in_channels = 10\n",
    "red_channels = 50\n",
    "batch = 1\n",
    "data = torch.rand(batch, in_channels, 256, 256)\n",
    "result = SqueezeExcitation(in_channels, red_channels)(data)\n",
    "\n",
    "assert data.shape == result.shape, \"Error: data and result shape does not match\"\n",
    "\n",
    "del in_channels, red_channels, batch, data, result\n",
    "\n",
    "print(\"Correct ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure shows Inverted Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dd](https://miro.medium.com/max/612/1*BaxdP8RS5x_EVMNJSd1Urg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Residual Block implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:33:45.477211Z",
     "start_time": "2022-01-07T13:33:45.470942Z"
    }
   },
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        expand_ratio= 1,\n",
    "        reduction = 4, # squeeze excitation\n",
    "        survival_prob= 0.8, # for stochastic depth\n",
    "    ):\n",
    "        '''\n",
    "        @param reduction: \n",
    "            How much we want to squeeze (see red_channels in SqueezeExcitation)\n",
    "            red_channels = in_channels / reduction\n",
    "        @param expand_ratio:\n",
    "            It is how much we want to increase the input_channels in the InvertedResidualBlock at the starting\n",
    "            We will not expand if it is equal to 1\n",
    "            new_input = input_channels * expand_ratio\n",
    "        @survival_prob:\n",
    "            It is used for the probability that if the layer should be removed or not\n",
    "            Sort of like Dropout for layers\n",
    "            How much percentage of layers we dont want to drop\n",
    "        '''\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        \n",
    "        self.survival_prob = survival_prob\n",
    "        \n",
    "        # If in_channels and out_channels are not same then we can sum them up for residual connection\n",
    "        # and stride should not be gt 1 becasue we want SAME CONV\n",
    "        self.use_residual = in_channels == out_channels and stride == 1\n",
    "#         print(in_channels, out_channels, self.use_residual, in_channels != out_channels)\n",
    "        \n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        \n",
    "        # Check if we can pull up residual connection or not\n",
    "        self.expand = in_channels != hidden_dim\n",
    "        \n",
    "        reduced_dim = int(in_channels / reduction)\n",
    "    \n",
    "        ##---- Expansion part ----##\n",
    "        # If expand_ratio > 1; then we can increase the channels to get new bigger channel input\n",
    "        if self.expand:\n",
    "            self.expand_conv = CNNBlock(\n",
    "                in_channels,\n",
    "                hidden_dim,\n",
    "                kernel_size=3,\n",
    "                stride= 1,\n",
    "                padding= 1\n",
    "            )\n",
    "\n",
    "        ##---- Squeeze Excitation part ----##\n",
    "        self.conv = nn.Sequential(\n",
    "            # Depth wise CNN\n",
    "            CNNBlock(hidden_dim, hidden_dim, kernel_size, stride, padding, groups= hidden_dim),\n",
    "            # Squeeze Excitation to update values of each channel by their AdaptiveAvgPool value\n",
    "            SqueezeExcitation(hidden_dim, reduced_dim),\n",
    "            # Do another conv\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "            \n",
    "            \n",
    "    def stochastic_depth(self, x):\n",
    "        '''\n",
    "        This function will remove random layers/block with some probability\n",
    "        Block here is refered to Inverted Residual Block\n",
    "        '''\n",
    "        if not self.training:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
    "        return torch.div(x, self.survival_prob) * binary_tensor\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Expand input if out expand_ration > 1\n",
    "        x = self.expand_conv(inputs) if self.expand else inputs\n",
    "        \n",
    "        if self.use_residual:\n",
    "            # remember stochastic_depth can return 0 valued Tensor so adding inputs can\n",
    "            # make them  non zero\n",
    "#             print(f\"{x.shape=}\")\n",
    "#             print(f\"{self.conv(x).shape=}\")\n",
    "#             print(f\"{self.stochastic_depth(self.conv(x)).shape=}\")\n",
    "#             print(f\"{(self.stochastic_depth(self.conv(x)) + inputs).shape=}\")\n",
    "            \n",
    "            return self.stochastic_depth(self.conv(x)) + inputs\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:11:23.427812Z",
     "start_time": "2022-01-07T13:11:23.417855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Binary tensor\n",
      "tensor([[[[False]]],\n",
      "\n",
      "\n",
      "        [[[ True]]],\n",
      "\n",
      "\n",
      "        [[[ True]]],\n",
      "\n",
      "\n",
      "        [[[ True]]]])\n",
      "---------- Layers\n",
      "tensor([[[[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2576, 1.0633],\n",
      "          [1.0067, 0.1463]]],\n",
      "\n",
      "\n",
      "        [[[0.5148, 0.0567],\n",
      "          [0.7111, 0.9424]]],\n",
      "\n",
      "\n",
      "        [[[0.2869, 0.9715],\n",
      "          [0.1948, 0.1353]]]])\n"
     ]
    }
   ],
   "source": [
    "## Stochastic Depth explanation (How it drops layers/block)\n",
    "x = torch.rand(4, 1, 2, 2)\n",
    "binary_tensor = torch.rand(4, 1, 1, 1) < 0.9\n",
    "print(\"-\"*10, \"Binary tensor\")\n",
    "print(binary_tensor)\n",
    "print(\"-\"*10, \"Layers\")\n",
    "print(torch.div(x, 0.9) * binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T09:08:33.731815Z",
     "start_time": "2022-01-08T09:08:33.722764Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#  Data for EfficientNet-B0 baseline network\n",
    "base_model = [\n",
    "    # expand_ratio, channels, repeats, stride, kernel_size\n",
    "    [1, 16, 1, 1, 3],\n",
    "    [6, 24, 2, 2, 3],\n",
    "    [6, 40, 2, 2, 5],\n",
    "    [6, 80, 3, 2, 3],\n",
    "    [6, 112, 3, 1, 5],\n",
    "    [6, 192, 4, 2, 5],\n",
    "    [6, 320, 1, 1, 3],\n",
    "]\n",
    "\n",
    "b = [0, 0, 0, 0, 0]\n",
    "\n",
    "phi_values = {\n",
    "    # tuple of: (phi_value, resolution, drop_rate)\n",
    "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n",
    "    \"b1\": (0.5, 240, 0.2),\n",
    "    \"b2\": (1, 260, 0.3),\n",
    "    \"b3\": (2, 300, 0.3),\n",
    "    \"b4\": (3, 380, 0.4),\n",
    "    \"b5\": (4, 456, 0.4),\n",
    "    \"b6\": (5, 528, 0.5),\n",
    "    \"b7\": (6, 600, 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:17:44.151726Z",
     "start_time": "2022-01-07T13:17:44.135168Z"
    }
   },
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, version, num_classes):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        \n",
    "        '''\n",
    "        Gettings factors to modify out layer depth, width, resoultion size and dropout rate\n",
    "        These factors are like parameters which then be multiplied by the no of channels,\n",
    "        no of layers and resolution\n",
    "        '''\n",
    "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
    "        \n",
    "        # See how width factor is multiplied by no of channels(1280) for the last layer channels\n",
    "        last_channels = math.ceil(1280 * width_factor)\n",
    "        \n",
    "        # Adaptive avg pool to get avg single no of each channel to sort of prioritize each channel\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Creating all the features for our network\n",
    "        self.features =self.create_features(width_factor, depth_factor, last_channels)\n",
    "        \n",
    "        # Classifier for last Fully connected layer\n",
    "        # Here dropout will be same for both in FullyConv layer and \"stochastic_depth\"\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(last_channels, num_classes),\n",
    "        )\n",
    "        \n",
    "    def calculate_factors(self, version:str, alpha:float= 1.2, beta:float= 1.1)-> tuple:\n",
    "        # specific values corresponding for the given version\n",
    "        phi, resolution, drop_rate = phi_values.get(version)\n",
    "        depth_factor = alpha**phi\n",
    "        width_factor = beta**phi\n",
    "        return width_factor, depth_factor, drop_rate\n",
    "    \n",
    "    \n",
    "    def create_features(self, width_factor, depth_factor, last_channels):\n",
    "        channels = int(32 * width_factor)\n",
    "        image_channels = 3 # (R, G, B)\n",
    "        \n",
    "        # Adding Step of the model to the features list\n",
    "        features = [CNNBlock(image_channels, channels, kernel_size=3, stride=2, padding= 1)]\n",
    "        \n",
    "        # in_channels will become the out_channels of the step layer\n",
    "        in_channels = channels\n",
    "        \n",
    "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
    "            # Just to make out_channels multiple of 4\n",
    "            out_channels = 4 * math.ceil(int(channels * width_factor) / 4)\n",
    "            \n",
    "            # Number of sub-layers we want in each layer\n",
    "            layers_repeat = ceil(repeats * depth_factor)\n",
    "            \n",
    "            # Creating sub-layer(s) for current layer\n",
    "            for layer in range(layers_repeat):\n",
    "                features.append(\n",
    "                    InvertedResidualBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        expand_ratio= expand_ratio,\n",
    "                        # -Stride will be 1 from the 2nd layer as we dont want to downsample it\n",
    "                        # -It only downsample for the first sub-layer in each layer\n",
    "                        # - Some layer dosen't downsample because their stride is already 1\n",
    "                        stride= stride if layer==0 else 1,\n",
    "                        \n",
    "                        kernel_size= kernel_size,\n",
    "                        # if k=1:pad=0, k=3:pad=1, k=5:pad=2 (FOR SAME CONV)\n",
    "                        # QUE: BUT! Someone may ask if we are doing SAME CONV for each layer, how will\n",
    "                        # our inputs are becoming smaller in resoultions???\n",
    "                        # ANS: Stride!, they are doing the real magic of resolution change.\n",
    "                        padding= kernel_size//2,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Dont forget to change in_channels for the next sub-layer!\n",
    "                in_channels = out_channels\n",
    "                \n",
    "        '''\n",
    "        This is the last layer of the model\n",
    "        Remember we create last_channels = math.ceil(1280 * width_factor)\n",
    "        ______________________________________________________________________\n",
    "        Stage | Operator               | Resolution | #Channels | #Layers\n",
    "        9     | Conv1x1 & Pooling & FC | 7 × 7      | 1280      | 1\n",
    "        ----------------------------------------------------------------------\n",
    "        '''\n",
    "        features.append(\n",
    "            CNNBlock(in_channels, last_channels, kernel_size= 1, stride=1, padding=0)\n",
    "        )\n",
    "        return nn.Sequential(*features)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Passing data from the conv layers and the doing average pool for each channel to make them single no\n",
    "        AdaptiveAvgPool(1)(batch_size, last_channels, H, W) = (batch_size, last_channels, 1, 1)\n",
    "        '''\n",
    "        x = self.pool(self.features(x))\n",
    "        \n",
    "        '''\n",
    "        Reshape the data and pass it to the fully connected layer(s)\n",
    "        '''\n",
    "        return self.classifier(x.view(x.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T13:34:24.343919Z",
     "start_time": "2022-01-07T13:34:24.059414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    version = \"b0\"\n",
    "    phi, res, drop_rate = phi_values[version]\n",
    "    num_examples, num_classes = 4, 10\n",
    "    x= torch.randn((num_examples, 3, res, res)).to(device)\n",
    "    model = EfficientNet(\n",
    "        version= version,\n",
    "        num_classes= num_classes\n",
    "    ).to(device)\n",
    "    \n",
    "    print(model(x).shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
